{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import operator\n",
    "import math\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rerun_filter_by_terms = True\n",
    "flag_clone = True\n",
    "flag_remove_old_files = True\n",
    "flag_copy_used_reports = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set experiment dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = dt.datetime.strptime('2005-01-01', '%Y-%m-%d')\n",
    "date_end = dt.datetime.strptime('2021-06-30', '%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_extension_start = dt.datetime.strptime('2018-01-01', '%Y-%m-%d')\n",
    "date_extension_end = dt.datetime.strptime('2021-06-30', '%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_series = list(range(date_start.year, date_end.year)) \n",
    "year_extension_series = list(range(date_extension_start.year, date_extension_end.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
      "[2018, 2019, 2020]\n"
     ]
    }
   ],
   "source": [
    "print(year_series)\n",
    "print(year_extension_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set root directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = os.path.join('..')\n",
    "dir_data_raw = os.path.join(dir_root, \"data_raw\")\n",
    "dir_data_processing = os.path.join(dir_root, \"data_processing\")\n",
    "dir_data_runs = os.path.join(dir_root, \"data_runs\")\n",
    "dir_ticker_prices_source = os.path.join(dir_data_raw, \"prices\", \"ready\")\n",
    "dir_ticker_prices_destination = os.path.join(dir_data_processing, \"prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set reports directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_reports_txt = os.path.join(dir_data_raw, 'reports_txt')\n",
    "dir_reports_words = os.path.join(dir_data_processing, 'reports_words')\n",
    "dir_reports_terms = os.path.join(dir_data_processing, 'reports_terms')\n",
    "dir_reports_grams = os.path.join(dir_data_processing, 'reports_gramms')\n",
    "dir_reports_ready =  os.path.join(dir_data_processing, 'reports_ready')\n",
    "dir_extention_reports = os.path.join(dir_data_processing, \"reports_ready_extentsion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set return files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_return_table = os.path.join(dir_ticker_prices_destination, \"all-returns.csv\")\n",
    "file_indices_table = os.path.join(dir_ticker_prices_destination, \"all-industries-indices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the base run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_to_extend_prefix = 'run_19_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prefix = \"run_19-ext_22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_run_to_extend = os.path.join(dir_data_runs, run_to_extend_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_run = os.path.join(dir_data_runs, run_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read tickers in the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 79 tickers\n",
      "AAL_FTSE\n",
      "ACA_CAC\n",
      "AC_CAC\n",
      "ADM_FTSE\n",
      "AGK_FTSE\n",
      "AIR_CAC\n",
      "ALV_DAX\n",
      "ANTO_FTSE\n",
      "BAB_FTSE\n",
      "BARC_FTSE\n",
      "BAYN_DAX\n",
      "BA_FTSE\n",
      "BMW_DAX\n",
      "BNP_CAC\n",
      "CAP_CAC\n",
      "CBK_DAX\n",
      "CSCO_DJIA\n",
      "CS_CAC\n",
      "CVX_DJIA\n",
      "DAI_DAX\n",
      "DBK_DAX\n",
      "DIS_DJIA\n",
      "DPW_DAX\n",
      "DTE_DAX\n",
      "EDF_CAC\n",
      "EI_CAC\n",
      "EOAN_DAX\n",
      "FRE_DAX\n",
      "GS_DJIA\n",
      "HD_DJIA\n",
      "HEN3_DAX\n",
      "HSBC_DJIA\n",
      "IFX_DAX\n",
      "JPM_DJIA\n",
      "KO_DJIA\n",
      "LHA_DAX\n",
      "LIN_DAX\n",
      "LLOY_FTSE\n",
      "LR_CAC\n",
      "MCD_DJIA\n",
      "MC_CAC\n",
      "MKS_FTSE\n",
      "MRO_FTSE\n",
      "MRW_FTSE\n",
      "MUV2_DAX\n",
      "OR_CAC\n",
      "PFC_FTSE\n",
      "PFE_DJIA\n",
      "PG_DJIA\n",
      "PRU_FTSE\n",
      "RBS_FTSE\n",
      "RB_FTSE\n",
      "REL_FTSE\n",
      "RI_CAC\n",
      "RRS_FTSE\n",
      "RSA_FTSE\n",
      "RWE_DAX\n",
      "SAP_DAX\n",
      "SBRY_FTSE\n",
      "SDF_DAX\n",
      "SHP_FTSE\n",
      "SIE_DAX\n",
      "SKY_FTSE\n",
      "SLA_FTSE\n",
      "SNN_FTSE\n",
      "SRP_FTSE\n",
      "SSE_FTSE\n",
      "TKA_DAX\n",
      "TSCO_FTSE\n",
      "TVE_DJIA\n",
      "ULVR_FTSE\n",
      "UTX_DJIA\n",
      "VED_FTSE\n",
      "VOD_FTSE\n",
      "VZ_DJIA\n",
      "WEIR_FTSE\n",
      "WMT_DJIA\n",
      "WPP_FTSE\n",
      "WTB_FTSE\n"
     ]
    }
   ],
   "source": [
    "tickers = set()\n",
    "\n",
    "with open(os.path.join(dir_run_to_extend, run_to_extend_prefix + '-documents.dat'), 'r') as f_r:\n",
    "    for line in f_r:\n",
    "        ticker = line.strip().split('-')[0]\n",
    "        tickers.add(ticker)\n",
    "        \n",
    "print('Read %s tickers' % len(tickers))\n",
    "\n",
    "for t in sorted(tickers):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read terms from run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_terms = os.path.join(dir_run_to_extend, '%s-terms.dat' % run_to_extend_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_term2id = {}\n",
    "dict_id2term = {}\n",
    "terms_set = set()\n",
    "term_list = []\n",
    "id_counter = 0\n",
    "\n",
    "with open(file_terms, 'r') as f_r:\n",
    "    for text_line in f_r:\n",
    "        term = text_line.strip()\n",
    "        terms_set.add(term)\n",
    "        term_list.append(term)\n",
    "        dict_term2id[term] = id_counter\n",
    "        dict_id2term[id_counter] = term\n",
    "        id_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dictionary: 21719 \n"
     ]
    }
   ],
   "source": [
    "print('Size of dictionary: %s ' % len(terms_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter reports by terms and store in extension folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create extension reports folder if doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_extention_reports):\n",
    "    os.makedirs(dir_extention_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_report_by_terms(report_file_name, report_dir, new_report_dir, dictionary):\n",
    "    report_path = os.path.join(report_dir, report_file_name)\n",
    "    with open(report_path, 'r', encoding='utf-8') as f_r:\n",
    "        new_terms = []\n",
    "        for text_line in f_r:\n",
    "            terms = text_line.strip().split(' ')\n",
    "            for term in terms:\n",
    "                if term in dictionary:\n",
    "                    new_terms.append(term)\n",
    "                \n",
    "                \n",
    "    new_report_path = os.path.join(new_report_dir, report_file_name)\n",
    "    with open(new_report_path, 'w') as f_w:\n",
    "        f_w.write(\"%s\" % ' '.join(new_terms))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ready_reports():\n",
    "    for report_file_name in os.listdir(dir_reports_ready):\n",
    "        if report_file_name == \".DS_Store\":\n",
    "            continue\n",
    "        filter_report_by_terms(report_file_name, \n",
    "                              dir_reports_ready,\n",
    "                              dir_extention_reports,\n",
    "                              terms_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_rerun_filter_by_terms:\n",
    "    filter_ready_reports()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone run to extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_clone:\n",
    "    if os.path.exists(dir_run):\n",
    "        shutil.rmtree(dir_run)\n",
    "        \n",
    "    shutil.copytree(dir_run_to_extend, dir_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build run data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read reports in extension period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_to_pull = set(year_series)\n",
    "reports_extension = {}\n",
    "amount_reports = 0\n",
    "\n",
    "for year in year_series:\n",
    "    reports_extension[year] = []\n",
    "\n",
    "for file_name in os.listdir(dir_extention_reports):\n",
    "    if file_name == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    ticker = file_name.split('-')[0]\n",
    "    if ticker not in tickers:\n",
    "        continue\n",
    "    \n",
    "    file_year = int(file_name.split('-')[1].split('_')[0])\n",
    "    if file_year not in year_to_pull:\n",
    "        continue\n",
    "        \n",
    "    reports_extension[file_year].append(file_name)\n",
    "    amount_reports += 1\n",
    "    \n",
    "for year in year_extension_series:\n",
    "    reports_extension[year] = sorted(reports_extension[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5562 new reports\n"
     ]
    }
   ],
   "source": [
    "print('We have %s new reports' % amount_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get amount of document in every year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restore amount of documents in every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2005 amount:234\n",
      "year: 2006 amount:268\n",
      "year: 2007 amount:274\n",
      "year: 2008 amount:285\n",
      "year: 2009 amount:303\n",
      "year: 2010 amount:302\n",
      "year: 2011 amount:304\n",
      "year: 2012 amount:301\n",
      "year: 2013 amount:320\n",
      "year: 2014 amount:335\n",
      "year: 2015 amount:382\n",
      "year: 2016 amount:363\n",
      "year: 2017 amount:368\n",
      "year: 2018 amount:0\n",
      "year: 2019 amount:0\n",
      "year: 2020 amount:0\n"
     ]
    }
   ],
   "source": [
    "amount_documents_in_series_dict = dict()\n",
    "\n",
    "for year in year_series:\n",
    "    amount_documents_in_series_dict[year] = 0\n",
    "    \n",
    "with open(os.path.join(dir_run, run_to_extend_prefix + '-seq.dat'), 'r') as f_r:\n",
    "    for i, line in enumerate(islice(f_r, 1, None)):\n",
    "        value = int(line.strip())\n",
    "        amount_documents_in_series_dict[date_start.year + i] = value\n",
    "\n",
    "for key, value in amount_documents_in_series_dict.items():\n",
    "    print('year: %s amount:%s' %(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update existing data and extend with new reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2005 amount:235\n",
      "year: 2006 amount:273\n",
      "year: 2007 amount:279\n",
      "year: 2008 amount:288\n",
      "year: 2009 amount:304\n",
      "year: 2010 amount:303\n",
      "year: 2011 amount:306\n",
      "year: 2012 amount:302\n",
      "year: 2013 amount:318\n",
      "year: 2014 amount:353\n",
      "year: 2015 amount:438\n",
      "year: 2016 amount:428\n",
      "year: 2017 amount:436\n",
      "year: 2018 amount:474\n",
      "year: 2019 amount:412\n",
      "year: 2020 amount:413\n"
     ]
    }
   ],
   "source": [
    "for year in year_series:\n",
    "    amount_documents_in_series_dict[year] = len(reports_extension[year])\n",
    "    \n",
    "for key, value in amount_documents_in_series_dict.items():\n",
    "    print('year: %s amount:%s' %(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove old file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_remove_old_files:\n",
    "    os.remove(os.path.join(dir_run, run_to_extend_prefix + '-seq.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of reports names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore reports names and extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 5562 reports\n"
     ]
    }
   ],
   "source": [
    "documents_name_list = list()\n",
    "\n",
    "#with open(os.path.join(dir_run, run_to_extend_prefix + '-documents.dat'), 'r') as f_r:\n",
    "#    for line in f_r:\n",
    "#        documents_name_list.append(line.strip())\n",
    "#print('Read %s reports' % len(documents_name_list))\n",
    "\n",
    "for year in year_series:\n",
    "    # the following line assumes that reports_extension[year] is sorted see a cell where we construct it\n",
    "    documents_name_list = documents_name_list + reports_extension[year]\n",
    "print('Combined %s reports' % len(documents_name_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove old file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_remove_old_files:\n",
    "    os.remove(os.path.join(dir_run, run_to_extend_prefix + '-documents.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vectorize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_report_dtm(file_report):\n",
    "    vector_report = list()\n",
    "    document_bow = dict()\n",
    "    with open(file_report, 'r') as f_r:\n",
    "        for text_line in f_r:\n",
    "            terms = text_line.strip().split(' ')\n",
    "            for term in terms:\n",
    "                term_id = dict_term2id[term]\n",
    "                if term_id not in document_bow:\n",
    "                    document_bow[term_id] = 0\n",
    "                document_bow[term_id] += 1\n",
    "            \n",
    "    for term_id, term_counter in document_bow.items():\n",
    "        vector_report.append(\"%s:%s\" % (term_id, term_counter))\n",
    "    \n",
    "    return vector_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore vecorized docs and extend with new reports in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 5562 reports\n"
     ]
    }
   ],
   "source": [
    "documents_vector_list = list()\n",
    " \n",
    "#with open(os.path.join(dir_run, run_to_extend_prefix + '-mult.dat'), 'r') as f_r:\n",
    "#    for line in f_r:\n",
    "#        document = list(islice(line.strip().split(' '), 1, None))\n",
    "#        documents_vector_list.append(document)\n",
    "#print('Read %s reports' % len(documents_vector_list))\n",
    "\n",
    "for year in year_series:\n",
    "    for report in reports_extension[year]:\n",
    "        report_path = os.path.join(dir_extention_reports, report)\n",
    "        document = vectorize_report_dtm(report_path)\n",
    "        documents_vector_list.append(document)\n",
    "print('Combined %s reports' % len(documents_vector_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove old file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_remove_old_files:\n",
    "    os.remove(os.path.join(dir_run, run_to_extend_prefix + '-mult.dat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate run files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize for DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save prefix-seq.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_run, run_prefix + '-seq.dat'), 'w') as f_w:\n",
    "    f_w.write(\"%s\\n\" % len(year_series))\n",
    "    for year in sorted(amount_documents_in_series_dict.keys()):\n",
    "        f_w.write(\"%s\\n\" % amount_documents_in_series_dict[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save prefix-mult.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_run, run_prefix + '-mult.dat'), 'w') as f_w:\n",
    "    for document in documents_vector_list:\n",
    "        f_w.write(\"%s %s\\n\" % (len(document), ' '.join(document)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize data for interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save prefix-documents.dat, every document the same order with mult.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_run, run_prefix + '-documents.dat'), 'w') as f_w:\n",
    "    for document in documents_name_list:\n",
    "        f_w.write(\"%s\\n\" % document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save prefix-terms.dat, with terms in ID order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dir_run, run_prefix + '-terms.dat'), 'w') as f_w:\n",
    "    for term in term_list:\n",
    "        f_w.write(\"%s\\n\" % term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy returns to the run folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_runs/run_19-ext_22/run_19-ext_22-returns.csv'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(file_return_table, os.path.join(dir_run, run_prefix + '-returns.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy industry indices returns to the run folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data_runs/run_19-ext_22/run_19-ext_22-industry-returns.csv'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile(file_indices_table, os.path.join(dir_run, run_prefix + '-industry-returns.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove old files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    if os.path.exists(filename): os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_remove_old_files:\n",
    "    silent_remove(os.path.join(dir_run, run_to_extend_prefix + '-terms.dat'))\n",
    "    silent_remove(os.path.join(dir_run, run_to_extend_prefix + '-returns.csv'))\n",
    "    silent_remove(os.path.join(dir_run, run_to_extend_prefix + '-industry-returns.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize run settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename run setting file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_setting_file = os.path.join(dir_run, run_to_extend_prefix + '-preprocesssing_settings.dat')\n",
    "new_setting_file = os.path.join(dir_run, run_prefix + '-preprocesssing_settings.dat')\n",
    "os.rename(old_setting_file, new_setting_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create result directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results = os.path.join(dir_run, 'results')\n",
    "\n",
    "if not os.path.exists(dir_results):\n",
    "    os.makedirs(dir_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_interpretation = os.path.join(dir_run, 'interpretation')\n",
    "\n",
    "if os.path.exists(dir_interpretation):\n",
    "    shutil.rmtree(dir_interpretation, ignore_errors=True)\n",
    "\n",
    "os.makedirs(dir_interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy reports for the run folder only if flag_copy_used_reports set True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_run_reports = os.path.join(dir_run, 'reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_copy_used_reports:\n",
    "    if not os.path.exists(dir_run_reports):\n",
    "        os.makedirs(dir_run_reports)    \n",
    "    for report_file_name in os.listdir(dir_reports_ready):\n",
    "        path_report_src = os.path.join(dir_reports_ready, report_file_name)\n",
    "        path_report_dst = os.path.join(dir_run_reports, report_file_name)\n",
    "\n",
    "        if report_file_name != '.DS_Store' and os.path.isfile(path_report_src):\n",
    "            shutil.copyfile(path_report_src, path_report_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
