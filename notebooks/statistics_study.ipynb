{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Important the notebook should be run after pre-processing notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import re\n",
    "import glob \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = dt.datetime.strptime(\"2005-01-01\", \"%Y-%m-%d\")\n",
    "date_end = dt.datetime.strptime(\"2021-06-30\", \"%Y-%m-%d\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n"
     ]
    }
   ],
   "source": [
    "year_series = list(range(date_start.year, date_end.year)) \n",
    "year_set = set(year_series)\n",
    "\n",
    "print(year_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '19-ext_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prefix = 'run_%s' % run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = os.path.join('..')\n",
    "dir_data_raw = os.path.join(dir_root, \"data_raw\")\n",
    "dir_data_processing = os.path.join(dir_root, \"data_processing\")\n",
    "\n",
    "dir_reports_pdf = os.path.join(dir_data_raw, \"reports_pdf\")\n",
    "dir_reports_txt = os.path.join(dir_data_raw, \"reports_txt\")\n",
    "\n",
    "dir_reports_words = os.path.join(dir_data_processing, \"reports_words\")\n",
    "dir_reports_terms = os.path.join(dir_data_processing, \"reports_terms\")\n",
    "dir_reports_gramms = os.path.join(dir_data_processing, \"reports_gramms\")\n",
    "dir_reports_ready = os.path.join(dir_data_processing, \"reports_ready\")\n",
    "dir_reports_ready_extension = os.path.join(dir_data_processing, \"reports_ready_extentsion\")\n",
    "\n",
    "dir_data_runs = os.path.join(dir_root, 'data_runs')\n",
    "dir_run = os.path.join(dir_data_runs, run_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_report_name_reg_exp = \"(?P<ticker>[A-Z1-9]+)[_-](?P<type>[A-Z]+)(?P<number>[1-9A-Z]*)(?P<subnumber>[_-]+[0-9]+)?[_-](?P<year>[0-9]{4})[_-](?P<p_year>[0-9]{4})\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Companies/reports stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_tickers = os.path.join(dir_data_processing, 'tickers')\n",
    "file_tickers_for_analysis = os.path.join(dir_data_tickers, 'ticker_for_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_fits_for_analysis = set()\n",
    "\n",
    "with open(file_tickers_for_analysis, 'r') as f_r:\n",
    "    for text_line in f_r:\n",
    "        ticker = text_line.strip()\n",
    "        tickers_fits_for_analysis.add(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to count dictionary size and average lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_stats(reports):\n",
    "    all_words_counter = 0\n",
    "    real_reports_counter = 0\n",
    "    dictionary = set()\n",
    "\n",
    "    for report in reports:\n",
    "        with open(report, 'r', encoding='ISO-8859-1') as f_r: #todo check encoding in pre-processing notebook\n",
    "            real_reports_counter += 1\n",
    "            for text_line in f_r:\n",
    "                words = re.split('\\s+', text_line.strip())\n",
    "                all_words_counter += len(re.split('\\s+', text_line.strip()))\n",
    "                for word in words:\n",
    "                    dictionary.add(word)\n",
    "    \n",
    "    return {\n",
    "        \"reports\": real_reports_counter,\n",
    "        \"average_length\": all_words_counter / (real_reports_counter if real_reports_counter > 0 else 1),\n",
    "        \"dictionary size\": len(dictionary),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove -copy from pdfs if there any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Copy\" files to investigate: 0 \n",
      "Removed 0 \"Copy\" files\n"
     ]
    }
   ],
   "source": [
    "path_glob_copy = os.path.join(dir_reports_pdf, '**', '**','*-copy.pdf')\n",
    "print('\"Copy\" files to investigate: %s ' % len(glob.glob(path_glob_copy)))\n",
    "\n",
    "removed = 0\n",
    "for report in sorted(glob.glob(path_glob_copy)):\n",
    "    original_report = report.replace('-copy', '');\n",
    "    if os.path.isfile(original_report):\n",
    "        removed += 1\n",
    "        os.remove(report)\n",
    "\n",
    "print('Removed %s \"Copy\" files' % removed)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_raw/reports_pdf/**/**/*.pdf\n",
      "9869\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_pdf, '**', '**','*.pdf')\n",
    "print(path_glob)\n",
    "    \n",
    "print(len(glob.glob(path_glob)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document available for study, raw in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_raw/reports_txt/**/**/*.txt\n",
      "{'reports': 9866, 'average_length': 39659.459051287246, 'dictionary size': 3374204}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_txt, '**', '**','*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "print(get_text_stats(sorted(glob.glob(path_glob))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document eligible for study, raw in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_raw/reports_txt/**/**/*.txt\n",
      "{'reports': 5613, 'average_length': 43848.557277748085, 'dictionary size': 2370384}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_txt, '**', '**','*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "reports = []\n",
    "for report in sorted(glob.glob(path_glob)):\n",
    "    components = report.split('/')\n",
    "    ticker = '%s_%s' % (components[4], components[3])\n",
    "    if ticker not in tickers_fits_for_analysis:\n",
    "        continue\n",
    "    match = re.search(check_report_name_reg_exp, components[-1])\n",
    "    publishing_year = None\n",
    "    \n",
    "    if match:\n",
    "        publishing_year = int(match.group(\"p_year\"))\n",
    "    else:\n",
    "        print(components[-1])\n",
    "        \n",
    "\n",
    "    if publishing_year not in year_set:\n",
    "        continue    \n",
    "    reports.append(report)\n",
    "\n",
    "print(get_text_stats(reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document eligible for study, superfluous character removaland lowercase conv in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_processing/reports_words/**/**/*.txt\n",
      "{'reports': 5598, 'average_length': 34730.845837799214, 'dictionary size': 238893}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_words, '**', '**','*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "reports = []\n",
    "for report in sorted(glob.glob(path_glob)):\n",
    "    components = report.split('/')\n",
    "    \n",
    "    ticker = '%s_%s' % (components[4], components[3])\n",
    "    if ticker not in tickers_fits_for_analysis:\n",
    "        continue\n",
    "    \n",
    "    match = components[-1].split('_')\n",
    "    publishing_year = int(match[0])\n",
    "    if publishing_year not in year_set:\n",
    "        continue    \n",
    "    \n",
    "    reports.append(report)\n",
    "\n",
    "print(get_text_stats(reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document eligible for study, noise removaland information concentration in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_processing/reports_terms/**/**/*.txt\n",
      "{'reports': 5596, 'average_length': 18968.560400285918, 'dictionary size': 29356}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_terms, '**', '**','*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "reports = []\n",
    "for report in sorted(glob.glob(path_glob)):\n",
    "    components = report.split('/')\n",
    "    \n",
    "    ticker = '%s_%s' % (components[4], components[3])\n",
    "    if ticker not in tickers_fits_for_analysis:\n",
    "        continue\n",
    "    \n",
    "    match = components[-1].split('_')\n",
    "    publishing_year = int(match[0])\n",
    "    if publishing_year not in year_set:\n",
    "        continue    \n",
    "    \n",
    "    reports.append(report)\n",
    "\n",
    "print(get_text_stats(reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document eligible for study, bigramms information concentration in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_processing/reports_gramms/**/**/*.txt\n",
      "{'reports': 5596, 'average_length': 18884.917619728378, 'dictionary size': 31513}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_gramms, '**', '**','*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "reports = []\n",
    "for report in sorted(glob.glob(path_glob)):\n",
    "    components = report.split('/')\n",
    "    \n",
    "    ticker = '%s_%s' % (components[4], components[3])\n",
    "    if ticker not in tickers_fits_for_analysis:\n",
    "        continue\n",
    "    \n",
    "    match = components[-1].split('_')\n",
    "    publishing_year = int(match[0])\n",
    "    if publishing_year not in year_set:\n",
    "        continue    \n",
    "    \n",
    "    reports.append(report)\n",
    "\n",
    "print(get_text_stats(reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of every document eligible for study, l_min l_max filters in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_processing/reports_ready/*.txt\n",
      "{'reports': 5649, 'average_length': 9483.41706496725, 'dictionary size': 24570}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_ready,'*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "print(get_text_stats(glob.glob(path_glob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_processing/reports_ready_extentsion/*.txt\n",
      "{'reports': 5649, 'average_length': 2536.343423614799, 'dictionary size': 21486}\n"
     ]
    }
   ],
   "source": [
    "path_glob = os.path.join(dir_reports_ready_extension,'*.txt')\n",
    "print(path_glob)\n",
    "\n",
    "print(get_text_stats(glob.glob(path_glob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the length of average length of a document from dtm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reports': 5344, 'average_length': 702.2249251497007}\n"
     ]
    }
   ],
   "source": [
    "dir_run\n",
    "file_mult = os.path.join(dir_run, '%s-mult.dat' % run_prefix)\n",
    "with (open(file_mult, 'r')) as f_r:\n",
    "    real_reports_counter = 0\n",
    "    all_words_counter = 0\n",
    "    for text_line in f_r:\n",
    "        real_reports_counter += 1\n",
    "        all_words_counter += int(text_line.strip().split(' ')[0])\n",
    "    print({\n",
    "        \"reports\": real_reports_counter,\n",
    "        \"average_length\": all_words_counter / real_reports_counter,\n",
    "    }) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
