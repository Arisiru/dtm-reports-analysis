{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3d6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccd077",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cdcef5",
   "metadata": {},
   "source": [
    "## Set experiment dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ee052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = dt.datetime.strptime(\"2005-01-01\", \"%Y-%m-%d\")\n",
    "date_end = dt.datetime.strptime(\"2021-06-30\", \"%Y-%m-%d\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e6cb5",
   "metadata": {},
   "source": [
    "## Set root directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b445f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_root = os.path.join('..')\n",
    "dir_data_processing = os.path.join(dir_root, \"data_processing\")\n",
    "dir_data_runs = os.path.join(dir_root, \"data_runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a52d7",
   "metadata": {},
   "source": [
    "## Set reports directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a61341",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_reports_words = os.path.join(dir_data_processing, \"reports_words\")\n",
    "dir_reports_terms = os.path.join(dir_data_processing, \"reports_terms\")\n",
    "dir_reports_grams = os.path.join(dir_data_processing, \"reports_gramms\")\n",
    "dir_reports_ready = os.path.join(dir_data_processing, \"reports_ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76f05b",
   "metadata": {},
   "source": [
    "## Set run directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee0e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prefix = 'run_19-ext_22'\n",
    "dir_run = os.path.join(dir_data_runs, run_prefix)\n",
    "dir_result_interpretation = os.path.join(dir_run, 'interpretation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76f934",
   "metadata": {},
   "source": [
    "## Set time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33cb0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_series = list(range(date_start.year, date_end.year)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ec3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n"
     ]
    }
   ],
   "source": [
    "print(year_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e9604",
   "metadata": {},
   "source": [
    "# Build dictionary of a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e98865",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_terms = os.path.join(dir_run, '%s-terms.dat' % run_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70835d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fixed dictionary: 21719 \n"
     ]
    }
   ],
   "source": [
    "dictionary_term2id = {}\n",
    "dictionary_id2term = {}\n",
    "term_id_counter = 0\n",
    "with open(file_terms, 'r') as f_r:\n",
    "    for text_line in f_r:\n",
    "        term = text_line.strip()\n",
    "        dictionary_term2id[term] = term_id_counter\n",
    "        dictionary_term2id[term_id_counter] = term\n",
    "        term_id_counter += 1\n",
    "        \n",
    "print('Size of fixed dictionary: %s ' % term_id_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e9796",
   "metadata": {},
   "source": [
    "# Construct binary reports vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b57db",
   "metadata": {},
   "source": [
    "## Read names of reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4272d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_report_info(name):\n",
    "    name = name.strip().split('.')[0]\n",
    "    components = name.split('-')\n",
    "    year, index = components[1].split('_')\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'year': int(year),\n",
    "        'ticker': components[0],\n",
    "        'index': int(index),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891c7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 5562 reports\n",
      "Read 79 tickers\n"
     ]
    }
   ],
   "source": [
    "reports = [] #{name, year, ticker, index}\n",
    "tickers = set()\n",
    "with open(os.path.join(dir_run, '%s-documents.dat' % run_prefix), 'r') as f_r:\n",
    "    for line in f_r:\n",
    "        report = expand_report_info(line)\n",
    "        tickers.add(report['ticker'])\n",
    "        reports.append(report)\n",
    "\n",
    "tickers_list = list(sorted(tickers))        \n",
    "\n",
    "print('Read %s reports' % len(reports))\n",
    "print('Read %s tickers' % len(tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e407a6d",
   "metadata": {},
   "source": [
    "## Map BOW to binary reports (P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f082e7",
   "metadata": {},
   "source": [
    "Read BOW for all reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20f6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(os.path.join(dir_run, '%s-mult.dat' % run_prefix), 'r')\n",
    "reports_bow = text_file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfba231",
   "metadata": {},
   "source": [
    "Construct P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_by_year = {}\n",
    "\n",
    "for ticker in tickers_list:\n",
    "    p = {}\n",
    "    for year in year_series:\n",
    "        p[year] = np.zeros(term_id_counter)\n",
    "    \n",
    "    P_by_year[ticker] = p\n",
    "    \n",
    "\n",
    "for i, report in enumerate(reports):\n",
    "    for j, term in enumerate(reports_bow[i].split(' ')):\n",
    "        if j == 0: continue\n",
    "        \n",
    "        P_by_year[report['ticker']][report['year']][int(term.split(':')[0])] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5538cb",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e44ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL_FTSE in 2007 has 1886.0 unique terms\n"
     ]
    }
   ],
   "source": [
    "test_ticker = 'AAL_FTSE'\n",
    "test_year = 2007\n",
    "total_term_in_P = 0\n",
    "for appearance in P_by_year[test_ticker][test_year]:\n",
    "    total_term_in_P += appearance \n",
    "\n",
    "    \n",
    "print('%s in %s has %s unique terms' % (test_ticker, test_year, total_term_in_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b77358",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_by_year = {}\n",
    "\n",
    "for ticker in tickers_list:\n",
    "    v = {}\n",
    "    for year in year_series:\n",
    "        v[year] = P_by_year[ticker][year] / np.sqrt(np.dot(P_by_year[ticker][year], np.ones(term_id_counter)))\n",
    "        \n",
    "    V_by_year[ticker] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c649c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL_FTSE in 2007 values in V scaled 0.0230265649529252\n"
     ]
    }
   ],
   "source": [
    "test_ticker = 'AAL_FTSE'\n",
    "test_year = 2007\n",
    "v = None\n",
    "    \n",
    "print('%s in %s values in V scaled %s' % (test_ticker, test_year, np.max(V_by_year[test_ticker][test_year])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcf186c",
   "metadata": {},
   "source": [
    "# Stability of a ticker (based on P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebcd416",
   "metadata": {},
   "source": [
    "Get number of 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95609373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_1s(x):\n",
    "    return x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da943082",
   "metadata": {},
   "source": [
    "Get number of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a94ffe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_0s(x):\n",
    "    return len(x) - x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d4a25",
   "metadata": {},
   "source": [
    "Partial Hamming distance: \"Became 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5380ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_hamming_distance_0(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 1 and y[i] == 0:\n",
    "            distance += 1\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d683e7",
   "metadata": {},
   "source": [
    "Partial Hamming distance: \"Became 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "103d35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_hamming_distance_1(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 0 and y[i] == 1:\n",
    "            distance += 1\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1d887",
   "metadata": {},
   "source": [
    "Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "066cf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(x, y, normalise=True):\n",
    "    distance = 0\n",
    "    size = max(x.sum(), y.sum())\n",
    "    diff = np.logical_xor(x, y)\n",
    "    distance = diff.sum() \n",
    "    if normalise:\n",
    "        distance /= size\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf90f11",
   "metadata": {},
   "source": [
    "Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "365ec1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(x, y):\n",
    "    intersection = np.logical_and(x, y)\n",
    "    union = np.logical_or(x, y)\n",
    "    distance = intersection.sum() / float(union.sum())\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac91ffa",
   "metadata": {},
   "source": [
    "Hober-phillipps similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5106d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_distance(x, y):\n",
    "    distance = np.dot(x, y)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70945cff",
   "metadata": {},
   "source": [
    "# Metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "048dc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for ticker in tickers_list:\n",
    "    ticker_p_years = P_by_year[ticker]\n",
    "    data_0s = [number_0s(ticker_p_years[year_series[0]])]\n",
    "    data_1s = [number_1s(ticker_p_years[year_series[0]])]\n",
    "    turn_0s = []\n",
    "    turn_1s = []\n",
    "    for i in range(1, len(year_series)):\n",
    "        data_0s.append(\n",
    "            number_0s(ticker_p_years[year_series[i]])\n",
    "        )\n",
    "        data_1s.append(\n",
    "            number_1s(ticker_p_years[year_series[i]])\n",
    "        )\n",
    "        turn_0s.append(\n",
    "            part_hamming_distance_0(\n",
    "                ticker_p_years[year_series[i - 1]],\n",
    "                ticker_p_years[year_series[i]]))\n",
    "        turn_1s.append(\n",
    "            part_hamming_distance_1(\n",
    "                ticker_p_years[year_series[i - 1]],\n",
    "                ticker_p_years[year_series[i]]))                 \n",
    "    \n",
    "    data[ticker] = [\n",
    "        np.array(data_0s).mean(),\n",
    "        np.array(data_1s).mean(),\n",
    "        np.array(turn_0s).mean(),\n",
    "        np.array(turn_1s).mean()\n",
    "    ]\n",
    "    \n",
    "df_data = pd.DataFrame(\n",
    "            data = data,\n",
    "            columns=tickers_list)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e499334e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AAL_FTSE       ACA_CAC        AC_CAC      ADM_FTSE      AGK_FTSE  \\\n",
      "0  19420.0625  19134.437500  21018.937500  20711.437500  20844.625000   \n",
      "1   2298.9375   2584.562500    700.062500   1007.562500    874.375000   \n",
      "2    495.0000    668.533333    270.333333    350.333333    283.000000   \n",
      "3    626.0000    611.866667    216.200000    345.466667    373.133333   \n",
      "\n",
      "        AIR_CAC       ALV_DAX     ANTO_FTSE    BAB_FTSE     BARC_FTSE  ...  \\\n",
      "0  19944.125000  19897.250000  20334.812500  20280.3125  19213.125000  ...   \n",
      "1   1774.875000   1821.750000   1384.187500   1438.6875   2505.875000  ...   \n",
      "2    544.933333    486.466667    337.133333    321.4000    519.066667  ...   \n",
      "3    613.933333    638.866667    403.266667    401.6000    586.466667  ...   \n",
      "\n",
      "       TVE_DJIA     ULVR_FTSE      UTX_DJIA  VED_FTSE      VOD_FTSE  \\\n",
      "0  19842.000000  19889.875000  20459.062500  19835.75  19255.250000   \n",
      "1   1877.000000   1829.125000   1259.937500   1883.25   2463.750000   \n",
      "2    368.533333    420.666667    391.133333    488.60    504.266667   \n",
      "3    444.533333    470.066667    485.266667    573.80    621.200000   \n",
      "\n",
      "        VZ_DJIA   WEIR_FTSE    WMT_DJIA      WPP_FTSE      WTB_FTSE  \n",
      "0  20407.312500  20239.1875  20542.3125  18942.812500  20456.875000  \n",
      "1   1311.687500   1479.8125   1176.6875   2776.187500   1262.125000  \n",
      "2    378.200000    352.6000    325.6000    826.666667    312.533333  \n",
      "3    409.066667    477.0000    354.6000    790.600000    373.800000  \n",
      "\n",
      "[4 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4789777",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_TEMPLATE1 = '''\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "  h2 {\n",
    "    text-align: center;\n",
    "    font-family: Helvetica, Arial, sans-serif;\n",
    "  }\n",
    "  table { \n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "  }\n",
    "  table, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "  }\n",
    "  th, td {\n",
    "    padding: 5px;\n",
    "    text-align: center;\n",
    "    font-family: Helvetica, Arial, sans-serif;\n",
    "    font-size: 90%;\n",
    "  }\n",
    "  table tbody tr:hover {\n",
    "    background-color: #dddddd;\n",
    "  }\n",
    "  .wide {\n",
    "    width: 90%; \n",
    "  }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "'''\n",
    "\n",
    "HTML_TEMPLATE2 = '''\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1aab1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_html_pretty(df, filename='/tmp/out.html', title=''):\n",
    "    '''\n",
    "    Write an entire dataframe to an HTML file\n",
    "    with nice formatting.\n",
    "    Thanks to @stackoverflowuser2010 for the\n",
    "    pretty printer see https://stackoverflow.com/a/47723330/362951\n",
    "    '''\n",
    "    ht = ''\n",
    "    if title != '':\n",
    "        ht += '<h2> %s </h2>\\n' % title\n",
    "    ht += df.to_html(classes='wide', escape=False)\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "         f.write(HTML_TEMPLATE1 + ht + HTML_TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8cb8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_file = os.path.join(dir_run, 'interpretation', 'stability_table.html')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c506ef8",
   "metadata": {},
   "source": [
    "      <th>Ticker</th>\n",
    "      <th>Mean 0s</th>\n",
    "      <th>Mean 1s</th>\n",
    "      <th>Mean turn to 0s</th>\n",
    "      <th>Mean turn to 1s</th>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "701f07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_html_pretty(df_data.transpose(), filename=table_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396eee8",
   "metadata": {},
   "source": [
    "Plot distance between consecutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_on_page = 5\n",
    "columns_on_page = 2\n",
    "plots_on_page = rows_on_page * columns_on_page\n",
    "number_of_pages = math.ceil(len(tickers) / plots_on_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_hp_distance_plots = os.path.join(dir_result_interpretation, 'hoberg_phillipps_distance_plot')\n",
    "\n",
    "if not os.path.exists(dir_hp_distance_plots):\n",
    "    os.makedirs(dir_hp_distance_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ee384",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ticker_iterator = 0\n",
    "\n",
    "bar_width = 1\n",
    "bar_l = [i for i in range(len(year_series))]\n",
    "tick_pos = [i for i in bar_l]\n",
    "\n",
    "for page in range(number_of_pages):\n",
    "    \n",
    "    f, axs = plt.subplots(\n",
    "        rows_on_page,\n",
    "        columns_on_page,\n",
    "        figsize=(10,11.5), # A4 landscape(11.69,8.27)\n",
    "        ) \n",
    "    \n",
    "    f.suptitle('Hamming and Jaccard distances between consecutive years', fontsize=16)\n",
    "    f.tight_layout(pad=3.0)\n",
    "    for row_index in range(rows_on_page):\n",
    "        for column_index in range(columns_on_page):\n",
    "            ax = axs[row_index][column_index]\n",
    "            \n",
    "            if global_ticker_iterator >= len(tickers_list):\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            if column_index == 0:\n",
    "                ax.set_ylabel(\"Distance to previous year\")\n",
    "            if row_index ==  rows_on_page - 1:\n",
    "                ax.set_xlabel(\"Years\")\n",
    "                \n",
    "            ticker = tickers_list[global_ticker_iterator]\n",
    "            ax.set_title('%s' % (ticker))\n",
    "\n",
    "\n",
    "            # data construction\n",
    "            ticker_p_years = P_by_year[ticker]\n",
    "            ticker_v_years = V_by_year[ticker]            \n",
    "            ## jaccard\n",
    "            data_jaccard = [1]\n",
    "            for i in range(1, len(year_series)):\n",
    "                data_jaccard.append(jaccard_distance(ticker_p_years[year_series[i - 1]], ticker_p_years[year_series[i]]))\n",
    "            ax.plot(np.asarray(data_jaccard, dtype=np.float64), color='blue', label='Jaccard distance')\n",
    "            \n",
    "            ## hamming\n",
    "            data_hamming = [0]\n",
    "            for i in range(1, len(year_series)):\n",
    "                data_hamming.append(hamming_distance(ticker_p_years[year_series[i - 1]], ticker_p_years[year_series[i]]))\n",
    "            ax.plot(np.asarray(data_hamming, dtype=np.float64), color='red', label='Hamming distance (normalize by number of terms in reprorts)')\n",
    "            \n",
    "            ## hamming\n",
    "            data_hp_sim = [1]\n",
    "            for i in range(1, len(year_series)):\n",
    "                data_hp_sim.append(hp_distance(ticker_v_years[year_series[i - 1]], ticker_v_years[year_series[i]]))\n",
    "            ax.plot(np.asarray(data_hp_sim, dtype=np.float64), color='black', label='Hoberg-Phillipps distance')\n",
    "            \n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_xticks(tick_pos)\n",
    "            ax.set_xticklabels(year_series, rotation=45, rotation_mode=\"anchor\", horizontalalignment='right')\n",
    "            \n",
    "            global_ticker_iterator += 1\n",
    "            \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    lgd = ax.legend(handles, labels, \n",
    "        bbox_to_anchor=(-0.74, -1.5), \n",
    "        loc=\"lower center\", \n",
    "        ncol=2, \n",
    "        handleheight=2.4, \n",
    "        labelspacing=0.05, prop={'size': 12})\n",
    "        \n",
    "    #save plot\n",
    "    pp = PdfPages(os.path.join(dir_hp_distance_plots, 'hp_similarity_on_page_%s.pdf' % page))\n",
    "    plt.savefig(pp, format='pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    pp.close()\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae923f80",
   "metadata": {},
   "source": [
    "Create a df with hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tickers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f563a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
